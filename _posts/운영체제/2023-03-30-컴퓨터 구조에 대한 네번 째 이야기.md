---
title: 컴퓨터 구조에 대한 네번 째 이야기
date: 2023-03-30
categories: [윈도우즈시스템프로그래밍, 운영체제]
tags: [windows]		# TAG는 반드시 소문자로 이루어져야함!
---

메모리 범위와 종류
====================

* 보통 메모리라고 하면 메인 메모리에 해당하는 램을 생각하지만 메모리는
`컴퓨터를 구성하는 요소 중에서 임시적이든, 영구적이든 저장 기능을 조금이라도 가지고 있으면 무조건 메모리의 범위로 포함`한다.

* 보통 메인메모리와 하드디스크를 비교하면 메인 메모리는 실행, 하드디스크는 저장의 기능으로 비교하지만 하드디스크는 실행이라는 기능도 가지고 있다.

<br><br>

## 메인 메모리
----------------
* 정확히는 D램(D-RAM)계열의 메모리

* 메인 메모리는 반드시 램이어야할 이유는 없다.

    * 따라서 메인 메모리와 램에는 등호관계가 성립하지 않는다.

  * 그러나 대부분 메인메모리를 램으로 사용한다.

<br>

## 레지스터
----------------
* 레지스터들도 당연히 메모리.

* CPU안에 내장되어 있어서 연산을 위한 저장소를 제공한다.

<br>

## 캐쉬
----------------

* 캐쉬는 D램보다 빠른 S램(S-RAM)으로 구성하는데, 램이라는 단어는 메인 메모리를 의미하는 용도로 사용되므로, 캐쉬 메모리는 캐쉬라고 부른다.

* 캐쉬는 CPU와 램 사이에서 중간 저장소 역할을 하는 메모리이다.

* 캐쉬가 CPU에 내장되어 있다고 표현하기도 하는데, `캐쉬 메모리는 원래 CPU의 일부로 존재하는 메모리 개념이 아니다. CPU에 근접해 있는 메모리 개념이다.`

* CPU의 일부로 존재하는 메모리는 레지스터이다.

<br>

## 하드디스크와 이외의 저장 장치들
----------------

* 하드디스크는 크고 작은 파일들을 저장하기 위한 용도로 사용되지만, 프로그램 실행에 있어서도 중요한 의미를 지닌다.

* 그밖에 SD카드,CD_ROM과 같은 I/O 장치들도 메모리에 해당한다.

* 프로그래머는 레지스터,캐쉬, 메인 메모리,하드디스크뿐만 아니라 그 밖의 I/O 장치들과의 입/출력 타이밍 및 대기 시간 등을 가장 중요한 요소로 생각하고 항상 고민해야 한다.

<br><br>

메모리 계층 구조
==========================

* 프로그램이 실행되는 동안 메모리가 하는 역할은 데이터의 입출력이다.

    * 따라서 기본적인 역할은 모든 메모리가 동일하다.


* 하지만 차이점이 존재하는데 가장 큰 차이점은 `CPU를 기준으로 얼마나 떨어져 있느냐`이다.

* 레지스터 > 캐쉬 메모리 > 메인 메모리 > 하드 디스크 순으로 CPU에 가깝다.

* CPU와 가까이 있을수록 빠르고, 멀리 있을수록 느리다.

* 그렇다면 가장 가까운 레지스터만 사용하면 가장 빠르겠지만 문제는 기술과 비용이 든다.

    * CPU 근처로 대용량의 메모리를 가져 갈수록 기술적인 문제들과 비용이 훨씬 많이 든다

<br><br>

### 계층 구조
------------

<br><br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/메모리%20계층%20구조.png" width=500 height =400></p>

<br>

* 가장 위쪽에 있는 것은 레지스터

  * 크기가 가장 작지만 가장 빠르다

* 그 다음 L1 캐쉬와 L2 캐쉬가 존재하다.

  * L1캐쉬가 L2캐쉬보다 CPU에 근접해 있다.

* 그 다음은 메인 메모리.

  * 캐쉬보다는 크지만 상대적으로 느리다.

* 그 다음은 하드 디스크.

  * 가장 크지만 가장 느리다.

<br>


### 원리
-------------



* CPU는 메인 메모리에게 데이터를 요청한다.

* 메인 메모리가 갖고 있으면,바로 CPU에게 주지만 없으면 하드 디스크에 요청한다.

* 하드 디스크는 그 데이터 블럭을 메인 메모리에게 올려준다.

* 그래서 메인 메모리는 CPU에게 데이터를 넘겨준다.

* ALU가 L1 캐시에 데이터를 요청한다. (레지스터가 아님.)

*  L1 캐시가 갖고 있지 않으면 L1 캐시는 L2 캐시에게 요청한다.

*  L2 캐시가 갖고 있지 않으면 메인 메모리에게 요청한다.

* 메인 메모리에게 없으면 하드 디스크에게 요청한다.

* 하드 디스크에 있었으면 메인 메모리에 데이터를 올려주는 등, 역으로 아래에서 위로 데이터를 올려주고를 반복해서 CPU까지 전달한다.

* 근데, CPU에서 바로 하드디스크로 접근해서 데이터를 요청하는게 빠르지 않을까 생각할 수 있다.

  * 만약 프로그램의 실행 흐름이 산발적이라면(여기저기 랜덤으로 실행) 하드디스크의 요청이 더 빠를 수도 있다.

  * 하지만 지역적인 특성을 지니기 때문에, 메모리가 계층적인 것이 더 성능이 향상된다.

    * 지역적인 특성은 실행 흐름이 여기저기서 실행하는 것이 아닌 어느 지역에 국한되어서 실행됨을 의미

<br><br>

캐쉬와 캐쉬 알고리즘
=======================

* 캐쉬 메모리가 존재했을 떄 성능이 향상되는 이유는 프로그램의 일반적인 특성 Locality가 존재하기 때문이다.

* 캐쉬메모리는 Temporal Locality와 Spatial Locality 두가지 특성을 지니고 있다.

<br>

## Temporal Locality (반복 접근)
-----------
* `프로그램 실행시 한 번 접근이 이뤄진 주소의 메모리 영역은 자주 접근하게 된다는 프로그램 특성`


<br>

## Spatial Locality (주변 접근)
-----------

* `프로그램 실행시 접근하는 메모리 영역은 이미 접근이 이루어진 영역의 근처일 확률이 높다는 프로그램 성격을 표현할 떄 사용하는 말`

* cpu가 필요한 데이터를 캐쉬 메모리에 요구할 때 있을 확률이 90%가 넘는데 그 이유가 바로 Spatial Locality 때문이다.

  * 밑에서 이야기하는 데이터 블록 단위 이동이 곧 Spatial Locality의 특징이다.

<br>

## 캐쉬 알고리즘
---------------

* Temporal Locality와 Spatial Locality의 특성이 캐쉬에 어떻게 반영하는지에 대한 과정

<br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/캐쉬%20알고리즘.png" width=600 height =400></p>

<br>

* Cpu가 L1에 캐쉬를 요구한다고 가정했을 때

* L1 `캐쉬에 해당 데이터가 존재할 경우를 캐쉬 힛이 발생`했다고 하며, 이 데이터를 레지스터로 이동시킨다.

* 반대로 L1 `캐쉬에 해당 데이터가 존재하지 않을 경우 캐쉬 미스가 발생`했다고 하고, 캐쉬 미스가 발생하면 L2 캐쉬에서 해당 데이터를 가져오게 된다.

  * L 2캐쉬에도 없다면 그 밑의 계층인 메인메모리에서 데이터를 가져온다.

<br>

* 메모리 사이에서 데이터의 이동은 블록 단위로 진행이 된다.

  * 메모리의 피라미드 구조 아래로 갈수록 블록 크기는 커진다.

  * 이는 피라미드 구조 아래에 존재하는 메모리일 수록 접근 횟수를 줄이는 효과를 가져다 준다.

<br>

* Cpu가 캐쉬에게 데이터를 요청했을 때, 그 데이터만 요구하는게 아닌 그 데이터를 포함한 데이터 블록을 전달하기 때문에 다음번에 데이터를 요청했을 때 확률이 높아지는 것이다.

  * 블록단위 전송이 이뤄지기 때문에 캐쉬 메모리에 데이터가 있을 확률이 90퍼가 넘는 이유.

<br>

### 캐쉬 미스가 발생할 떄 고려하게 되는 부분
-----------
* 운영체제가 동작하고, 프로그램이 실행되는 동안 하드 디스크를 제외한 모든 메모리가 항상 채워져 있다.

* L2캐쉬의 경우 캐쉬 메모리를 채워놔야만 L1 캐쉬에서 요구하는 데이터를 소유하고 있을 확률이 높아지기 때문에 조금이라도 비워둘 필요가 없다.

* 그런데 L1 캐쉬에서 캐쉬미스가 발생해서 L2캐쉬로부터 데이터 블록을 읽어 들일 때 해당 데이터 블록을 L1 캐쉬에 저장을 해야하는데 저장하려면 기존 L1 캐쉬 데이터를 밀어야 한다.

* 이 때 보편적으로 거론되는 알고리즘이 LRU 알고리즘이다.

  * LRU 알고리즘 : 가장 오래전에 참조된 블록을 밀어내는 알고리즘

<br>

## 캐쉬 프렌드리 코드 
--------------

* 캐쉬의 도움을 많이 받을수 있도록 구현하는 코드

```c++
int total = 0;
for(int i = 0;i < 10;i++)
{
  for(int j = 0;j < 10;j++)
  {
    total+= arr[i][j];
  }
}

// arr[0][0] -> arr[1][0] 보다 arr[0][0] -> arr[0][1] 같이 해당 데이터의 근처에 있을수록 좋음

```

* 산발적인 접근이 아닌 순차적으로 접근했을 때가 캐쉬의 도움을 받을 수 있다.

<br><br>

가상 메모리
===============

* CPU가 요구하는 메모리 공간이 2GB라고 했을 때 메인 메모리가 가지고 있는 공간이 256MB라고 한다면 부족한 메모리 공간을 채워주기 위해 더 큰 메모리 공간을 지닌 하드디스크까지 확장해서 사용한다.

* `하드디스크까지 확장해서 메모리 공간을 넓히는 것을 가상 메모리 기법`이라고 한다.

* 가상 메모리에는 가상 주소와 물리 주소가 있다.

<br>

## 물리주소
------------------

* `데이터는 컴파일이 완료된 운영체제와 그 운영체제를 바탕으로 동작하는 프로그램을 총칭하는 것`이다.

<br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/임베디드%20시스템의%20동작%20원리.png" width=600 height =300></p>

<br>

* 위 그림에서는 운영체제 코드와 프로그램을 하나의 바이너리 코드로 생성해서 시스템에 로딩한다.

* 위 그림의 램 용량을 16MB라고 가정한다면 임베디드 시스템에서 접근 가능한 메모리 영역은 0번지부터 "(16 x 1024 x 1024) -1"번지까지 사이가 된다.

  * 이 접근 가능한 메모리 영역이 바로 실제 물리적인 메인 메모리의 주소 범위에 해당한다.

  * 이렇게 `주소를 할당하는 것을 가리켜 물리적 주소 지정`이라고 한다.

    * 물리적 주소 지정의 특징은 메인 메모리 크기에 따라 지정 가능한 주소의 범위가 결정된다는 것이다.

<br>

* 물리적 주소 지정을 하게 되면 CPU 입장에서는 접근 가능한 주소의 범위가 제한된다.
  * 이것은 프로그래머가 할당할 수 있는 주소 범위도 제한적이라는 뜻도 된다.

* 이렇게 주소 범위가 제한되면 프로그래머는 주소 범위를 넘지 않게 개발해야하기 때문에 상당한 제약사항으로 작용한다.

* 이러한 제약 사항을 겪지 않게 하기 위해 가상 주소 시스템을 사용한다.

<br><br>

## 가상 주소 시스템 1
---------------------

* 32비트 시스템에서 프로세스 생성시 4GB의 메모리를 할당받을 수 있다.

* 하지만 메인 메모리의 크기는 턱없이 부족하다.

* 따라서 4GB는 실제 존재하지 않는 가상의 주소라는 것을 알 수 있다.

  * 이렇게 `가상의 주소를 지정하는 것을 가상 주소 지정`이라 한다.

  * `가상 주소 지정을 통해 할당받는 4GB를 가리켜 가상 메모리 공간`이라 한다.

<br>

* 하드 디스크까지 확장하여 사용하는 가상 메모리 기법을 사용할 때 고려해야할 점이 있다.

* 가상 메모리 시스템의 원리를 배우고 나면 이 두 문제를 해결하기 위한 방법은 해결할 수 있다.

<br>

### 1.선 할당으로 인한 부담
------------------

* 프로세스를 생성할 시 4GB씩 할당해줄 것인지

* 아주 작은 프로그램(ex) "Hello World")를 실행시킬 때에도 4GB씩 할당할지

<br>

### 2.느린 속도의 개선 필요성
-----------------

* 메인 메모리와 하드 디스크는 속도에 차이가 있어 생기는 문제

<br><br>

가상 메모리 시스템의 원리 1
==============

* 가상 메모리 시스템을 구현하는 방법은 표준으로 정해져 있지는 않다.

* 그러나 대부분의 시스템에서는 페이징(Paging)이라는 기법을 사용하므로 이를 바탕으로 설명한다.

  * 페이징 알고리즘의 구현방법은 다양하여 구현이 아닌 이해의 관점으로 본다.

<br><br>

### 가상 메모리 시스템을 설명하기 위한 약간의 설정
----------------

```
밑에서 설명할 시스템의 사양
-------------------------
가정 1. 16비트 시스템. 따라서 0부터 64K-1까지 주소 지정 가능
가정 2. 프로세스별로 64K바이트 메모리 할당, 물론 가상 메모리 할당
가정 3. 메인 메모리 16K바이트, 즉 램 용량이 16K바이트
```

<br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/풀어야할%20문제의%20도입.png" width=500 height = 400></p>

<br>

* 실제 메모리는 16K 바이트이지만, 프로세스를 생성할 때마다 64K바이트를 할당하고자 하니 문제가 생긴다.

  * 특히 16K번지 이상의 메모리는 접근조차 불가능

  * 최대 할당 가능한 메모리는 16K-1번지까지

<br>

* 이 문제를 해결하기 위해 다음과 같은 구조를 생각한다.


<br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/가상 메모리와 MMU.png" width=500 height = 500></p>

<br>

* 첫번째 요청에서 16KB가 있다고 가정할 때 CPU는 실제보다 더 큰 메모리가 있다고 생각하고 MMU에게 요구하는데 1K번지부터 20바이트 할당을 요청한다.

* 여기서 20바이트를 할당할 때 메인 메모리를 블럭 단위로 할당하기 때문에 1K번지에 해당하는 0 - 4K를 할당한다.

  * 메모리 블럭 단위를 4K라고 가정

* 두번째 요청에서 36K번지에서 20바이트를 요청하면 순차적으로가 아니라 그 다음 블록을 순간순간적으로 바로 결정짓기 때문에 36K - 40K를 할당한다.

* 여기서 실제 물리적인 주소를 생각하면 36K - 40K는 4K에 해당한다.

* CPU가 만약 36K에 있는 데이터를 요청한다면 MMU는 물리 메모리 4K에 있는 데이터를 가져다 CPU에게 전달한다.

  * CPU가 가상 메모리로 접근한다면 MMU는 물리 메모리로 접근하고 그 메모리를 CPU에게 전달한다.

<BR>

* 즉, `MMU(Memory management unit)는 존재하지 않는 메모리를 존재하는 것 처럼 CPU가 느끼도록 컨트롤 하는 역할`이다.
    * CPU가 실제보다 더 큰 메모리가 있다고 가정하여 존재하지 않는(기존 보다 큰) 메모리를 요청하기 때문에 MMU가 해결하는 구조.


<br><br>

가상 메모리 시스템의 원리 2
===========

* 가상 메모리 시스템의 원리 1에서는 물리메모리와 가상 메모리에 대한 설명이고 2는 페이지와 페이지 프레임에 대한 설명이다.

<br>

## 페이지 & 페이지 프레임
----------------

* `소프트웨어 입장에서의 메모리 블록을 페이지` 라고 부른다.

* `하드웨어 입장에서의 메모리 블록을 페이지 프레임`이라고 부른다

* 페이지 단위로 데이터를 할당하고 페이지 프레임 단위로 데이터를 해제하기 때문에 페이지와 페이지 프레임의 크기는 같다.


<br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/페이지%20테이블의%20구성.png" width=600 height = 500></p>

<br>

* 위 그림은 **가상 메모리(페이지)**와 그에 해당하는 **실제 메모리(페이지 프레임)**가 어떻게 매핑되는지 보여준다.


<br><br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/스왑%20파일과%20메인%20메모리.png" width=600 height = 300></p>

<br>

* 느린속도를 개선하기 위해 하드디스크의 일부까지 메인메모리를 확대하는 것이 가상메모리, 실질적인 메모리는 RAM에 국한된다고 이야기 했었다.

* RAM에 접근할 때는 빨라지고 하드디스크에 접근해질 때는 느려지기 때문에 하드디스크와 RAM의 관계를 Cash관계로 구성한다.

  * RAM부터 하드디스크까지 2GB라고 한다면 2GB의 메모리 공간 전부를 하드디스크에 넣어버린다.

  * Temporal Locality와 Spatial Locality에 의해 메모리를 블록단위로 하드디스크에 놓고 RAM은 그 블록을 가져다가 사용하는 형태.

<br><br>

* 속도가 빠른 램과 메모리가 큰 하드디스크의 역할을 완전시 동일시 해서 등장하기 때문에 이러한 문제점이 나타난 것이다.

* 하드디스크는 스왑파일을 통해서 메인 메모리를 보조하고 램과 동일한 성격의 메인 메모리 역할을 하는것이 아니기 때문에 발생한 것.

<br><br>

### 하드디스크의 역할
--------

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/하드디스크의%20역할%20-%201.png" width=600 height = 500></p>

<br>

* 램이 꽉찬 상태에서 CPU로부터 4-8K를 할당하겠다는 명령이 들어오면 램은 자리를 내어주기 위해 한 메모리 블럭을 빼야한다.

* 가장 오래 사용되지 않은 메모리 블럭인 8-12K를 하드디스크에 옮기고 그 자리에 4-8K의 메모리 블럭을 할당한다.

* 만약 하드디스크로 옮겨진 8-12K를 다시 할당한다면 들어온 4-8K가 아닌, 똑같이 가장 오래 사용되지 않은 메모리 블럭을 빼내고 다시 할당하는 형태로 구성된다.

* `하드디스크는 저장할 때 파일시스템기반으로 저장하는데 이러한 프로세스의 가상 메모리 확장을 위해 메모리 공간에 파일을 저장하는 것을 스왑파일`이라고 한다.

<br><br>

둘 이상의 프로세스와 가상 메모리
=================

* 가상 메모리에서 하드디스크의 역할에 대해 살펴보았는데, 이를 바탕으로 둘 이상의 메모리가 큰 프로세스에게 어떻게 할당이 가능한지 설명할 수 있다.

<br>

<p align="center"><img src="./../../assets/img/윈도우즈%20시스템%20프로그래밍/컴퓨터%20구조에%20대한%20네번%20째%20이야기/둘%20이상의%20프로세스%20지원.png" width=500 height = 400></p>

<br>

```
- 프로세스 A가 실행을 멈추고 프로세스 B를 실행시킨다고 가정한다.

1. 현재 메인 메모리중 RAM은 프로세스 A를 실행시키기 위한 데이터가 존재한다.

2. 프로세스 B를 실행하기 전에 RAM에 존재하는 프로세스 A의 실행을 위한 데이터 모두를 프로세스 A 스왑파일에 저장한다.

3. 프로세스 B의 실행을 위한 데이터를 프로세스 B 스왑파일로부터 램에 가져다 놓는다.
```

* 이러한 과정을 반복하여 둘 이상의 프로세스가 각각 할당받아 실행을 이어가는 것ㄷ이다.

* 이러한 메모리를 채우고 비우고하는 것도 콘텍스트 스위칭에 해당하기 때문에 부담이 크다.